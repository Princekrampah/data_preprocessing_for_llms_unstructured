{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.partition.pptx import partition_pptx\n",
    "from unstructured.staging.base import dict_to_elements\n",
    "\n",
    "import chromadb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = UnstructuredClient(\n",
    "    api_key_auth=os.getenv(\"UNSTRUCTURED_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./example_datasets/donut_paper.pdf\"\n",
    "\n",
    "with open(filename, \"rb\") as f:\n",
    "    files=shared.Files(\n",
    "        content=f.read(),\n",
    "        file_name=filename,\n",
    "    )\n",
    "\n",
    "req = shared.PartitionParameters(\n",
    "    files=files,\n",
    "    strategy=\"hi_res\",\n",
    "    hi_res_model_name=\"yolox\",\n",
    "    pdf_infer_table_structure=True,\n",
    "    skip_infer_table_types=[],\n",
    ")\n",
    "\n",
    "try:\n",
    "    resp = s.general.partition(req)\n",
    "    pdf_elements = dict_to_elements(resp.elements)\n",
    "except SDKError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': '59a9f0edd370eaa8c5c59cd9256e63bd',\n",
       " 'text': 'OCR-free Document Understanding Transformer',\n",
       " 'metadata': {'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 1,\n",
       "  'filename': 'donut_paper.pdf'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [el for el in pdf_elements if el.category == \"Table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html = tables[0].metadata.text_as_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <tr>\n",
      "    <td>NAVER CLOVA 4Upstage</td>\n",
      "    <td>2NAVER Search STmax 6Google</td>\n",
      "    <td>3SNAVER AI Lal 7LBox</td>\n",
      "  </tr>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO \n",
    "from lxml import etree\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "file_obj = StringIO(table_html)\n",
    "tree = etree.parse(file_obj, parser)\n",
    "print(etree.tostring(tree, pretty_print=True).decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Out References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_title = [\n",
    "    el for el in pdf_elements\n",
    "    if el.text == \"References\"\n",
    "    and el.category == \"Title\"\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': '05db3e5dd95df32622138973f0d4b9ed',\n",
       " 'text': 'References',\n",
       " 'metadata': {'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 15,\n",
       "  'parent_id': 'f6fdb355e327d011494e182b9f994661',\n",
       "  'filename': 'donut_paper.pdf'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_title.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05db3e5dd95df32622138973f0d4b9ed'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_id = reference_title.id\n",
    "references_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Afzal, M.Z., Capobianco, S., Malik, M.I., Marinai, S., Breuel, T.M., classification with Dengel, A., Liwicki, M.: Deepdocclassifier: Document deep convolutional neural network. In: 2015 13th International Conference on Document Analysis and Recognition (ICDAR). pp. 1111–1115 (2015). https://doi.org/10.1109/ICDAR.2015.7333933 1, 4, 14\n"
     ]
    }
   ],
   "source": [
    "for element in pdf_elements:\n",
    "    if element.metadata.parent_id == references_id:\n",
    "        print(element)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_elements = [el for el in pdf_elements if el.metadata.parent_id != references_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Out Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [el for el in pdf_elements if el.category == \"Header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Header',\n",
       " 'element_id': 'a4b916e36299d9c6f3f676a6480f550c',\n",
       " 'text': 'OCR-free Document Understanding Transformer',\n",
       " 'metadata': {'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 3,\n",
       "  'filename': 'donut_paper.pdf'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_elements = [el for el in pdf_elements if el.category != \"Header\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess PPTX Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./example_datasets/donut_slide.pptx\"\n",
    "pptx_elements = partition_pptx(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Markdown File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Reading document from string ...\n",
      "INFO: Reading document ...\n"
     ]
    }
   ],
   "source": [
    "filename = \"./example_datasets/donut_readme.md\"\n",
    "md_elements = partition_md(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = chunk_by_title(pdf_elements + pptx_elements + md_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CompositeElement',\n",
       " 'element_id': '0f7a2a45-4278-49ff-a19c-842b06606043',\n",
       " 'text': 'OCR-free Document Understanding Transformer\\n\\n2 2 0 2\\n\\nGeewook Kim1∗, Teakgyu Hong4†, Moonbin Yim2†, Jeongyeon Nam1, Jinyoung Park5†, Jinyeong Yim6†, Wonseok Hwang7†, Sangdoo Yun3, Dongyoon Han3, and Seunghyun Park1\\n\\nt c O 6',\n",
       " 'metadata': {'filename': 'donut_paper.pdf',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 1,\n",
       "  'orig_elements': 'eJzVU01v1DAQ/SujnBdInMTecC0SqyJaRLdCValWk3gcrN3YkdehhIr/znjVRStUDj1VXCzNmzdfb8a3DxntaCAXN1ZnbyGrG2xMTlqXKifEZVd3ddPpRtSSZNnqbAHZQBE1RmT+Q2bsjhwOlIK1d1PcjDhSeD1qk7jJHefx4MZx3NkOo/XuzaN7h66fsKc9+28zcn12x+jIyMZNQ0uB8eIXQ5F+xJTj8uzzKxOI4J3vptQ3XDtNYR/Raet6WAd0e+PDwKEp7LH02sYdZZzo73nLtiGdy5yolSXVJMyyYQlk15pGSlm/xLwHJDxjJ6cCCRCQgzgd/tpxE9T7YH+SXifeE0IYqauqEq0SS6NUp1RRClSdrNpCGGrwvxPiPdG991v4YIfi6yREoRawJtz28wQr7/qKwVzkC/jovWutgxs7iCN2TsyY+YELHLiPc+tmP/F9fcKwrf+wGE3EFCqP4Bfv9sR1V/c8ojqiV2xo7+FmcuWCj5ezc1lYYTL5duGKOP23eXKHEsXp/i4wBBbvO/1rd6oRuc6LqlVlhQUZiYZUVTRIvEtRmZf+tBE6uAT5xIe8+w2E6WvW'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
